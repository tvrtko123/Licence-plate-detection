{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_dir = './train/images'\n",
    "label_dir = './train/labels'\n",
    "\n",
    "labels_dict = dict(filepath=[],xmin=[],xmax=[],ymin=[],ymax=[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for img_file in os.listdir(img_dir):\n",
    "    img_path = os.path.join(img_dir, img_file)\n",
    "    label_path = os.path.join(label_dir, img_file.replace(\".jpg\", \".txt\"))\n",
    "    \n",
    "    image = cv2.imread(img_path)\n",
    "    if image is None:\n",
    "        continue\n",
    "    \n",
    "    with open(label_path, \"r\") as f:\n",
    "        label = f.readline().strip().split()[1:]\n",
    "        label = [float(x) for x in label]\n",
    "        \n",
    "        x_points = label[::2]\n",
    "        y_points = label[1::2]\n",
    "        \n",
    "        img_h, img_w, _ = image.shape\n",
    "        x_points = [int(x * img_w) for x in x_points]\n",
    "        y_points = [int(y * img_h) for y in y_points]\n",
    "        \n",
    "        x_min = min(x_points)\n",
    "        x_max = max(x_points)\n",
    "        y_min = min(y_points)\n",
    "        y_max = max(y_points)\n",
    "        \n",
    "        labels_dict['filepath'].append(img_path)\n",
    "        labels_dict['xmin'].append(x_min)\n",
    "        labels_dict['xmax'].append(x_max)\n",
    "        labels_dict['ymin'].append(y_min)\n",
    "        labels_dict['ymax'].append(y_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(labels_dict)\n",
    "df.to_csv('labels.csv',index=False)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path = list(df['filepath'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = df.iloc[:,1:].values\n",
    "data = []\n",
    "output = []\n",
    "for ind in range(len(image_path)):\n",
    "    image = image_path[ind]\n",
    "    img_arr = cv2.imread(image)\n",
    "    h,w,d = img_arr.shape\n",
    "    load_image = tf.keras.utils.load_img(image,target_size=(224,224))\n",
    "    load_image_arr = tf.keras.utils.img_to_array(load_image)\n",
    "    norm_load_image_arr = load_image_arr/255.0\n",
    "    xmin,xmax,ymin,ymax = labels[ind]\n",
    "    nxmin,nxmax = xmin/w,xmax/w\n",
    "    nymin,nymax = ymin/h,ymax/h\n",
    "    label_norm = (nxmin,nxmax,nymin,nymax)\n",
    "    data.append(norm_load_image_arr)\n",
    "    output.append(label_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(data,dtype=np.float32)\n",
    "y = np.array(output,dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,x_test,y_train,y_test = train_test_split(X,y,train_size=0.8,random_state=0)\n",
    "x_train.shape,x_test.shape,y_train.shape,y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inception_resnet = tf.keras.applications.InceptionResNetV2(\n",
    "    weights=\"imagenet\",\n",
    "    include_top=False,\n",
    "    input_shape=(224, 224, 3)\n",
    ")\n",
    "inception_resnet.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "headmodel = inception_resnet.output\n",
    "headmodel = tf.keras.layers.Flatten()(headmodel)\n",
    "headmodel = tf.keras.layers.Dense(500,activation=\"relu\")(headmodel)\n",
    "headmodel = tf.keras.layers.Dense(250,activation=\"relu\")(headmodel)\n",
    "headmodel = tf.keras.layers.Dense(4,activation='sigmoid')(headmodel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Model(inputs=inception_resnet.input,outputs=headmodel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='mse',optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "class CustomModelCheckpoint(tf.keras.callbacks.Callback):\n",
    "    def __init__(self, save_freq_epochs=100, filepath='model_{epoch:03d}.keras'):\n",
    "        super(CustomModelCheckpoint, self).__init__()\n",
    "        self.save_freq_epochs = save_freq_epochs\n",
    "        self.filepath = filepath\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        if (epoch + 1) % self.save_freq_epochs == 0:\n",
    "            save_path = self.filepath.format(epoch=epoch + 1)\n",
    "            self.model.save(save_path)\n",
    "            print(f'\\nModel saved to {save_path}\\n')\n",
    "\n",
    "checkpoint_callback = CustomModelCheckpoint(save_freq_epochs=100, filepath='model_{epoch:03d}.keras')\n",
    "\n",
    "tfb = tf.keras.callbacks.TensorBoard('object_detection')\n",
    "\n",
    "history = model.fit(\n",
    "    x=x_train, y=y_train, \n",
    "    batch_size=10, epochs=300,\n",
    "    validation_data=(x_test, y_test), \n",
    "    callbacks=[tfb, checkpoint_callback]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model('./model_300.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss = model.evaluate(x_test, y_test)\n",
    "print(f\"Test MSE: {test_loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_iou(box1, box2):\n",
    "    x1_max = min(box1[1], box2[1])\n",
    "    x1_min = max(box1[0], box2[0])\n",
    "    y1_max = min(box1[3], box2[3])\n",
    "    y1_min = max(box1[2], box2[2])\n",
    "    \n",
    "    inter_area = max(0, x1_max - x1_min) * max(0, y1_max - y1_min)\n",
    "    \n",
    "    box1_area = (box1[1] - box1[0]) * (box1[3] - box1[2])\n",
    "    box2_area = (box2[1] - box2[0]) * (box2[3] - box2[2])\n",
    "    \n",
    "    iou = inter_area / float(box1_area + box2_area - inter_area)\n",
    "    return iou"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_map(ground_truths, predictions, iou_threshold=0.5):\n",
    "    \"\"\"Calculate mean Average Precision (mAP) at a specific IoU threshold.\"\"\"\n",
    "    aps = []\n",
    "    for pred_box, gt_box in zip(predictions, ground_truths):\n",
    "        iou = calculate_iou(gt_box, pred_box)\n",
    "        if iou >= iou_threshold:\n",
    "            aps.append(1.0)\n",
    "        else:\n",
    "            aps.append(0.0)\n",
    "\n",
    "    return np.mean(aps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_ar(predictions, ground_truths, iou_thresholds=[0.5, 0.75]):\n",
    "    recalls = []\n",
    "    for iou_threshold in iou_thresholds:\n",
    "        all_recalls = []\n",
    "        for pred_box, gt_box in zip(predictions, ground_truths):\n",
    "            iou = calculate_iou(pred_box, gt_box)\n",
    "            recall = iou >= iou_threshold\n",
    "            all_recalls.append(recall)\n",
    "\n",
    "        ar = np.mean(all_recalls)\n",
    "        recalls.append(ar)\n",
    "    \n",
    "    AR = np.mean(recalls)\n",
    "    return AR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_curve, average_precision_score\n",
    "from sklearn.metrics import PrecisionRecallDisplay\n",
    "\n",
    "def plot_precision_recall_curve(y_true, y_pred, label='PR Curve'):\n",
    "    precisions, recalls, thresholds = precision_recall_curve(y_true, y_pred)\n",
    "    avg_precision = average_precision_score(y_true, y_pred)\n",
    "\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.plot(recalls, precisions, marker='.', label=f'{label} (AP={avg_precision:.2f})')\n",
    "    plt.xlabel('Recall')\n",
    "    plt.ylabel('Precision')\n",
    "    plt.title('Precision-Recall Curve')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(x_test)\n",
    "\n",
    "denorm_factors = np.array([x_test.shape[2], x_test.shape[2], x_test.shape[1], x_test.shape[1]])\n",
    "y_pred_denorm = y_pred * denorm_factors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_denorm = y_test * denorm_factors\n",
    "\n",
    "predictions = [pred_box for pred_box in y_pred_denorm]\n",
    "ground_truths = [gt_box for gt_box in y_test_denorm]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = np.array(predictions)\n",
    "ground_truths = np.array(ground_truths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mAP = calculate_map(predictions, ground_truths)\n",
    "AR = calculate_ar(predictions, ground_truths)\n",
    "ious = [calculate_iou(pred, true) for pred, true in zip(y_pred, y_test)]\n",
    "mean_iou = np.mean(ious)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Mean Average Precision (mAP): {mAP:.2f}\")\n",
    "print(f\"Average Recall (AR): {AR:.2f}\")\n",
    "print(f\"Mean IoU: {mean_iou}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_iou_histogram(ious):\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.hist(ious, bins=20, color='skyblue', edgecolor='black')\n",
    "    plt.xlabel('IoU Score')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.title('IoU Score Distribution')\n",
    "    plt.show()\n",
    "\n",
    "plot_iou_histogram(ious)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_map_vs_iou(iou_thresholds, map_values):\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.plot(iou_thresholds, map_values, marker='o', color='blue')\n",
    "    plt.xlabel('IoU Threshold')\n",
    "    plt.ylabel('mAP')\n",
    "    plt.title('mAP vs. IoU Threshold')\n",
    "    plt.show()\n",
    "\n",
    "iou_thresholds = np.linspace(0.5, 0.95, 10)\n",
    "map_values = [calculate_map(ground_truths, predictions, threshold) for threshold in iou_thresholds]\n",
    "plot_map_vs_iou(iou_thresholds, map_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_cumulative_iou_curve(ious):\n",
    "    sorted_ious = sorted(ious)\n",
    "    cumulative = np.cumsum(sorted_ious) / len(ious)\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.plot(sorted_ious, cumulative, color='purple')\n",
    "    plt.xlabel('IoU Threshold')\n",
    "    plt.ylabel('Cumulative Distribution')\n",
    "    plt.title('Cumulative IoU Curve')\n",
    "    plt.show()\n",
    "\n",
    "plot_cumulative_iou_curve(ious)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def precision_recall_f1(ious, threshold=0.5):\n",
    "    true_positives = sum(iou > threshold for iou in ious)\n",
    "    false_positives = len(ious) - true_positives\n",
    "    false_negatives = len(y_test) - true_positives\n",
    "    \n",
    "    precision = true_positives / (true_positives + false_positives)\n",
    "    recall = true_positives / (true_positives + false_negatives)\n",
    "    f1_score = 2 * (precision * recall) / (precision + recall)\n",
    "    \n",
    "    return precision, recall, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision, recall, f1_score = precision_recall_f1(ious)\n",
    "print(f\"Precision: {precision:.2f}, Recall: {recall:.2f}, F1-Score: {f1_score:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def object_detection(path):\n",
    "    image = tf.keras.utils.load_img(path)\n",
    "    image = np.array(image,dtype=np.uint8)\n",
    "    image1 = tf.keras.utils.load_img(path,target_size=(224,224))\n",
    "    image_arr_224 = tf.keras.utils.img_to_array(image1)/255.0\n",
    "    h,w,d = image.shape\n",
    "    test_arr = image_arr_224.reshape(1,224,224,3)\n",
    "    coords = model.predict(test_arr)\n",
    "    denorm = np.array([w,w,h,h])\n",
    "    coords = coords * denorm\n",
    "    coords = coords.astype(np.int32)\n",
    "    xmin, xmax,ymin,ymax = coords[0]\n",
    "    pt1 =(xmin,ymin)\n",
    "    pt2 =(xmax,ymax)\n",
    "    print(pt1, pt2)\n",
    "    cv2.rectangle(image,pt1,pt2,(0,255,0),3)\n",
    "    return image, coords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def get_random_image_path(directory):\n",
    "    files = os.listdir(directory)\n",
    "    \n",
    "    files = [f for f in files if os.path.isfile(os.path.join(directory, f))]\n",
    "    \n",
    "    return os.path.join(directory, random.choice(files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = get_random_image_path(img_dir)\n",
    "print(path)\n",
    "image, cods = object_detection(path)\n",
    "\n",
    "plt.figure(figsize=(10,8))\n",
    "plt.imshow(image)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_path = path.strip(\"'\")\n",
    "matching_row = df[df['filepath'] == clean_path]\n",
    "if not matching_row.empty:\n",
    "    extracted_values = matching_row.iloc[0, 1:].tolist()\n",
    "    result = ', '.join(map(str, extracted_values))\n",
    "    print (result)\n",
    "    values = result.split(', ')\n",
    "else:\n",
    "    print(\"No matching row found.\")\n",
    "xmin,xmax,ymin,ymax = map(int, values)\n",
    "img = cv2.imread(path)\n",
    "cv2.rectangle(img, (xmin, ymin), (xmax, ymax), (0, 255, 0), 3)\n",
    "img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.imshow(img_rgb)\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
